{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "LV2BOKCReytD"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "from gensim.models import KeyedVectors\n",
        "from gensim.test.utils import datapath\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EEF5HAqqe0Lh",
        "outputId": "1d245552-f80f-44ae-bc7e-8eba70f5d73a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ooxvy3SuSH2R"
      },
      "source": [
        "## Explore vecmap alignments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "XPv9ggmwfAVY"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.spatial.distance import cosine\n",
        "from numpy.linalg import svd\n",
        "\n",
        "def load_embeddings(file_path, source, target, base_path=\"/content/drive/MyDrive/analogy/s2orc/20200705v1/full/level1.abstract.api/MUSE/\"):\n",
        "  src_vectors = KeyedVectors.load_word2vec_format(base_path+file_path+'vectors-'+source+'.txt', binary=False)\n",
        "  tgt_vectors = KeyedVectors.load_word2vec_format(base_path+file_path+'vectors-'+target+'.txt', binary=False)\n",
        "  return src_vectors, tgt_vectors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a6pjpvHNnihz",
        "outputId": "012b8120-766e-4031-87a0-15174bcb93ce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading hci-ling...\n",
            "loading hci-edu...\n",
            "loading ling-hci...\n",
            "loading ling-edu...\n",
            "loading ling-imm...\n",
            "loading edu-hci...\n",
            "loading edu-ling...\n",
            "loading hci-imm...\n",
            "loading hci-eth...\n",
            "loading hci-pro...\n",
            "loading ling-eth...\n",
            "loading ling-pro...\n",
            "loading edu-imm...\n",
            "loading edu-eth...\n",
            "loading edu-pro...\n"
          ]
        }
      ],
      "source": [
        "base_url = \"/content/drive/MyDrive/analogy/s2orc/20200705v1/full\"\n",
        "\n",
        "base_url_with_vecmap = base_url + \"/level1.abstract.api/vecmap\"\n",
        "\n",
        "paths = {\n",
        "    'hci-ling': ('participant.v6__hci--ling', 'hci', 'ling'),\n",
        "    'hci-edu': ('participant.v6__hci--edu', 'hci', 'edu'),\n",
        "    'ling-hci': ('participant.v6__ling--hci', 'ling', 'hci'),\n",
        "    'ling-edu': ('participant.v6__ling--edu', 'ling', 'edu'),\n",
        "    'ling-imm': ('participant.v6__ling--imm', 'ling', 'imm'),\n",
        "    'edu-hci': ('participant.v6__edu--hci', 'edu', 'hci'),\n",
        "    'edu-ling': ('participant.v6__edu--ling', 'edu', 'ling'),\n",
        "    'hci-imm': ('participant.v6__hci--imm', 'hci', 'imm'),\n",
        "    'hci-eth': ('participant.v6__hci--eth', 'hci', 'eth'),\n",
        "    'hci-pro': ('participant.v6__hci--pro', 'hci', 'pro'),\n",
        "    'ling-eth': ('participant.v6__ling--eth', 'ling', 'eth'),\n",
        "    'ling-pro': ('participant.v6__ling--pro', 'ling', 'pro'),\n",
        "    'edu-imm': ('participant.v6__edu--imm', 'edu', 'imm'),\n",
        "    'edu-eth': ('participant.v6__edu--eth', 'edu', 'eth'),\n",
        "    'edu-pro': ('participant.v6__edu--pro', 'edu', 'pro'),\n",
        "}\n",
        "community_names = ['hci', 'ling', 'edu', 'pro', 'eth', 'imm']\n",
        "embeds = {}\n",
        "for pair, (path, src, tgt) in paths.items():\n",
        "    print(f\"loading {src}-{tgt}...\")\n",
        "    embeds[src] = embeds.get(src, {})\n",
        "    embeds[src][tgt] = {}\n",
        "\n",
        "    embeds[src][tgt][\"src_emb\"] = KeyedVectors.load_word2vec_format(os.path.join(base_url_with_vecmap, f\"{path}/vectors-{src}.txt\"), binary=False)\n",
        "    embeds[src][tgt][\"tgt_emb\"] = KeyedVectors.load_word2vec_format(os.path.join(base_url_with_vecmap, f\"{path}/vectors-{tgt}.txt\"), binary=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def word_most_similar_same_emb(emb, word, n=10):\n",
        "  if word in emb:\n",
        "    return emb.most_similar(positive=[word], topn=n)\n",
        "  elif ' ' in word:\n",
        "    phrase = '__'.join(word.split(' '))\n",
        "    if phrase in emb:\n",
        "      return emb.most_similar(positive=[phrase], topn=n)\n",
        "  return None\n",
        "\n",
        "def src_word_most_similar_in_tgt(src_emb, tgt_emb, src_word, n=10):\n",
        "  if src_word in src_emb:\n",
        "    return tgt_emb.most_similar(positive=[ src_emb[src_word] ], topn=n)\n",
        "  elif ' ' in src_word:\n",
        "    \"\"\"\n",
        "    words = src_word.split(' ')\n",
        "    avg_emb = None\n",
        "    w_cnt = 0\n",
        "    for w in words:\n",
        "      if w not in src_emb:\n",
        "        continue\n",
        "      if avg_emb is None:\n",
        "        avg_emb = np.array(src_emb[w])\n",
        "      else:\n",
        "        avg_emb += src_emb[w]\n",
        "      w_cnt += 1\n",
        "    if avg_emb is not None:\n",
        "      avg_emb /= w_cnt\n",
        "      return tgt_emb.most_similar(positive=[ avg_emb ], topn=n)\n",
        "    \"\"\"\n",
        "    phrase = '__'.join(src_word.split(' '))\n",
        "    if phrase in src_emb:\n",
        "      return tgt_emb.most_similar(positive=[ src_emb[src_word] ], topn=n)\n",
        "  return None\n",
        "\n",
        "def src_word_rank_sim_in_tgt(src_emb, tgt_emb, src_word):\n",
        "  if src_word not in src_emb:\n",
        "    return None, None\n",
        "  for rank, w_sim in enumerate(tgt_emb.most_similar(positive=[ src_emb[src_word] ], topn=100000)):\n",
        "    tgt_word, sim = w_sim\n",
        "    if tgt_word == src_word:\n",
        "      return rank, sim\n",
        "  # match not found in topn\n",
        "  return None, None"
      ],
      "metadata": {
        "id": "g4XjRMdf25Vx"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "src_community = \"hci\" #choose one of: hci, edu, ling\n",
        "tgt_community = \"eth\" #choose onf of: hci, edu, ling, pro, eth, imm\n",
        "\n",
        "src_embed = embeds[src_community][tgt_community][\"src_emb\"]\n",
        "tgt_embed = embeds[src_community][tgt_community][\"tgt_emb\"]\n",
        "\n",
        "word = \"AI-mediated__communication\"\n",
        "cross_sim_list = src_word_most_similar_in_tgt(src_embed, tgt_embed, word)\n",
        "cross_sim_list\n",
        "# TODO: Make it easy to hook up with db\n",
        "# if cross_sim_list is None:\n",
        "#     pass\n",
        "# else:\n",
        "#     cross_res = []\n",
        "#     for w, sim in cross_sim_list:\n",
        "#         ctx_list = get_ctx_by_word(cur, w, tgt)\n",
        "#         cross_res.append({'word': w, 'sim': sim, 'ctx': process_ctx_list(ctx_list)})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ldzDble3KRI",
        "outputId": "92280032-0902-4a01-cb25-20ea51e3b406"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('wider', 0.8147139549255371),\n",
              " ('Chagrin', 0.8083021640777588),\n",
              " ('Falls', 0.8082398772239685),\n",
              " ('landscape', 0.7854062914848328),\n",
              " ('landmark', 0.7750949263572693),\n",
              " ('agenda', 0.7665138244628906),\n",
              " ('BAM', 0.7627230882644653),\n",
              " ('scientists', 0.7586003541946411),\n",
              " ('institutional', 0.7544519901275635),\n",
              " ('higher__education', 0.7536154985427856)]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}